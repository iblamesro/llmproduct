# EU AI Act - Key Requirements Summary

## Article 9: Risk Management System

High-risk AI systems shall be designed and developed with a risk management system that:

1. Identifies and analyzes known and foreseeable risks
2. Estimates and evaluates risks that may emerge during the use of the system
3. Evaluates risks based on data gathered from post-market monitoring
4. Adopts suitable risk management measures

### Risk Management Measures

Organizations must implement:
- Technical measures to mitigate identified risks
- Organizational measures including procedures and training
- Documentation of all risk assessments and mitigation strategies
- Regular review and updates of risk management processes

## Article 13: Transparency and Information

Providers of high-risk AI systems must ensure:
- Clear instructions for use
- Information about the intended purpose
- Level of accuracy, robustness, and cybersecurity
- Known limitations and circumstances that could lead to risks

## Article 14: Human Oversight

High-risk AI systems shall be designed to:
- Allow for effective oversight by natural persons
- Include appropriate human-machine interface tools
- Enable human intervention or interruption when necessary
- Provide information about the capabilities and limitations

## Compliance Requirements for Financial Institutions

Banks and financial institutions must:

1. **Establish AI Governance Framework**
   - Designate responsible AI officers
   - Create clear accountability structures
   - Document all AI systems and their risk classifications

2. **Conduct Regular Audits**
   - Annual compliance reviews
   - Third-party assessments when required
   - Documentation of audit findings and remediation

3. **Maintain Documentation**
   - Technical documentation for each AI system
   - Training data provenance
   - Model cards and performance metrics
   - Risk assessments and mitigation strategies

4. **Implement Monitoring Systems**
   - Post-market monitoring mechanisms
   - Incident reporting procedures
   - Regular performance evaluations

## Penalties for Non-Compliance

- Up to â‚¬30 million or 6% of worldwide annual turnover
- Criminal liability in cases of gross negligence
- Reputational damage and loss of customer trust

## Timeline

- Regulation enters into force: 20 days after publication
- High-risk systems compliance: 24 months from entry into force
- Full compliance for all systems: 36 months from entry into force

## Key Definitions

**High-Risk AI System**: AI systems that pose significant risks to health, safety, or fundamental rights

**Provider**: Entity that develops AI systems or has them developed with intent to place on market

**Deployer**: Entity using AI systems under its authority, except for personal non-professional use

---

*This is a simplified summary for educational purposes. Please refer to the official EU AI Act for complete requirements.*
